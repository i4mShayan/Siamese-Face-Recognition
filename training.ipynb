{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T11:54:56.677607Z",
     "iopub.status.busy": "2025-02-03T11:54:56.677301Z",
     "iopub.status.idle": "2025-02-03T11:55:00.063340Z",
     "shell.execute_reply": "2025-02-03T11:55:00.062120Z",
     "shell.execute_reply.started": "2025-02-03T11:54:56.677583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-03T11:55:00.065262Z",
     "iopub.status.busy": "2025-02-03T11:55:00.064921Z",
     "iopub.status.idle": "2025-02-03T11:55:00.074809Z",
     "shell.execute_reply": "2025-02-03T11:55:00.073943Z",
     "shell.execute_reply.started": "2025-02-03T11:55:00.065232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, ConcatDataset, TensorDataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder, CelebA\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision.transforms import ToTensor, Compose, Resize\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torchvision.utils as vutils\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T11:55:00.076751Z",
     "iopub.status.busy": "2025-02-03T11:55:00.076519Z",
     "iopub.status.idle": "2025-02-03T11:55:00.092325Z",
     "shell.execute_reply": "2025-02-03T11:55:00.091620Z",
     "shell.execute_reply.started": "2025-02-03T11:55:00.076730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: Pins Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T11:55:00.093877Z",
     "iopub.status.busy": "2025-02-03T11:55:00.093576Z",
     "iopub.status.idle": "2025-02-03T11:55:47.499411Z",
     "shell.execute_reply": "2025-02-03T11:55:47.498635Z",
     "shell.execute_reply.started": "2025-02-03T11:55:00.093847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_url = 'https://www.kaggle.com/datasets/hereisburak/pins-face-recognition/data'\n",
    "dataset_path = '/kaggle/input/105_classes_pins_dataset'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root=dataset_path, transform=transform)\n",
    "class_to_idx = dataset.class_to_idx\n",
    "num_classes = len(class_to_idx)\n",
    "\n",
    "# Extract labels for stratification\n",
    "labels = [label for _, label in dataset]\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T11:55:47.500472Z",
     "iopub.status.busy": "2025-02-03T11:55:47.500229Z",
     "iopub.status.idle": "2025-02-03T11:55:47.873367Z",
     "shell.execute_reply": "2025-02-03T11:55:47.872606Z",
     "shell.execute_reply.started": "2025-02-03T11:55:47.500445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load dataset to get class names\n",
    "full_dataset = ImageFolder(root=dataset_path, transform=transform)\n",
    "class_names = list(full_dataset.class_to_idx.keys())  # Get class (person) names\n",
    "\n",
    "# Select 30 random classes to INCLUDE\n",
    "random.seed(42)  # Ensure reproducibility\n",
    "included_classes = set(random.sample(class_names, 30))\n",
    "print(f\"Including {len(included_classes)} classes: {included_classes}\")\n",
    "\n",
    "# Define a custom dataset that includes only the selected classes\n",
    "class FilteredImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None, included_classes=set()):\n",
    "        super().__init__(root, transform=transform)\n",
    "        self.filtered_samples = [\n",
    "            (path, label) for path, label in self.samples\n",
    "            if self.classes[label] in included_classes\n",
    "        ]\n",
    "        self.samples = self.filtered_samples\n",
    "        self.targets = [s[1] for s in self.samples]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "# Load the filtered dataset\n",
    "dataset = FilteredImageFolder(dataset_path, transform=transform, included_classes=included_classes)\n",
    "\n",
    "# Create DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Print dataset size after filtering\n",
    "print(f\"Filtered dataset size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T11:55:47.874522Z",
     "iopub.status.busy": "2025-02-03T11:55:47.874274Z",
     "iopub.status.idle": "2025-02-03T11:55:59.292964Z",
     "shell.execute_reply": "2025-02-03T11:55:59.292134Z",
     "shell.execute_reply.started": "2025-02-03T11:55:47.874501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate the number of images per class\n",
    "image_count_per_class = {class_name: 0 for class_name in class_to_idx.keys()}\n",
    "for _, label in dataset:\n",
    "    class_name = list(class_to_idx.keys())[list(class_to_idx.values()).index(label)]\n",
    "    image_count_per_class[class_name] += 1\n",
    "\n",
    "# Total number of images\n",
    "total_images = len(dataset)\n",
    "\n",
    "# Print dataset stats\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Total number of images: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T11:55:59.299852Z",
     "iopub.status.busy": "2025-02-03T11:55:59.299653Z",
     "iopub.status.idle": "2025-02-03T11:56:00.228917Z",
     "shell.execute_reply": "2025-02-03T11:56:00.228019Z",
     "shell.execute_reply.started": "2025-02-03T11:55:59.299834Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of image count per class\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(image_count_per_class.keys(), image_count_per_class.values())\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Distribution of Image Count per Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T11:56:00.230211Z",
     "iopub.status.busy": "2025-02-03T11:56:00.229956Z",
     "iopub.status.idle": "2025-02-03T11:56:00.857847Z",
     "shell.execute_reply": "2025-02-03T11:56:00.856963Z",
     "shell.execute_reply.started": "2025-02-03T11:56:00.230188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get a batch of data\n",
    "images, labels = next(iter(data_loader))\n",
    "\n",
    "# Plot the batch of images\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Batch of Images\")\n",
    "grid_img = vutils.make_grid(images[:16], nrow=4, normalize=True)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamease Network (Triple Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T11:56:00.892932Z",
     "iopub.status.busy": "2025-02-03T11:56:00.892724Z",
     "iopub.status.idle": "2025-02-03T11:56:00.907872Z",
     "shell.execute_reply": "2025-02-03T11:56:00.907176Z",
     "shell.execute_reply.started": "2025-02-03T11:56:00.892913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom ImageFolder with filtering applied\n",
    "class FilteredImageFolder(ImageFolder):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.targets = [s[1] for s in self.samples]\n",
    "        self.classes = sorted(set([s[1] for s in self.samples]))  # Unique class labels\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        self.transform = transform\n",
    "        self.loader = default_loader  # ✅ Fix: Define the image loader correctly\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = self.loader(path)  # ✅ Now, the loader is correctly defined\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "        \n",
    "class TripletDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset):\n",
    "        self.subset = subset\n",
    "        self.class_indices = self._get_class_indices()\n",
    "    \n",
    "    def _get_class_indices(self):\n",
    "        \"\"\"Create a mapping from class labels to dataset indices.\"\"\"\n",
    "        class_indices = {}\n",
    "        for subset_idx, (_, label) in enumerate(self.subset):\n",
    "            if label not in class_indices:\n",
    "                class_indices[label] = []\n",
    "            class_indices[label].append(subset_idx)\n",
    "        \n",
    "        # Convert to numpy arrays for efficient sampling\n",
    "        return {k: np.array(v) for k, v in class_indices.items()}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns a (anchor, positive, negative) triplet.\"\"\"\n",
    "\n",
    "        # Select anchor image and its label\n",
    "        anchor, anchor_label = self.subset[idx]\n",
    "\n",
    "        # Ensure there are at least 2 images in this class\n",
    "        if len(self.class_indices[anchor_label]) < 2:\n",
    "            raise ValueError(f\"Not enough samples for anchor class {anchor_label}\")\n",
    "\n",
    "        # Select a positive sample (same class)\n",
    "        positive_indices = self.class_indices[anchor_label]\n",
    "        positive_idx = random.choice(positive_indices[positive_indices != idx])\n",
    "        positive, _ = self.subset[positive_idx]\n",
    "\n",
    "        # Select a negative sample (different class)\n",
    "        negative_labels = [l for l in self.class_indices.keys() if l != anchor_label]\n",
    "\n",
    "        # Ensure there are available negative samples\n",
    "        if not negative_labels:\n",
    "            raise ValueError(\"No negative samples available for triplet loss training!\")\n",
    "\n",
    "        negative_label = random.choice(negative_labels)\n",
    "        negative_idx = random.choice(self.class_indices[negative_label])\n",
    "        negative, _ = self.subset[negative_idx]\n",
    "\n",
    "        return anchor, positive, negative\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T11:56:00.908874Z",
     "iopub.status.busy": "2025-02-03T11:56:00.908601Z",
     "iopub.status.idle": "2025-02-03T11:56:00.925076Z",
     "shell.execute_reply": "2025-02-03T11:56:00.924431Z",
     "shell.execute_reply.started": "2025-02-03T11:56:00.908847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "augmented_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Randomly crop and resize\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip horizontally\n",
    "    transforms.RandomRotation(degrees=45),  # Random rotation\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random translation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color properties\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T11:56:00.925913Z",
     "iopub.status.busy": "2025-02-03T11:56:00.925731Z",
     "iopub.status.idle": "2025-02-03T11:56:00.940794Z",
     "shell.execute_reply": "2025-02-03T11:56:00.940215Z",
     "shell.execute_reply.started": "2025-02-03T11:56:00.925897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def augment_dataset(X, y, augmentation_transform, num_augmentations=1):\n",
    "    \"\"\"Expands dataset by adding augmented versions of images.\"\"\"\n",
    "    augmented_X, augmented_y = [], []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        original_image = X[i]\n",
    "        augmented_X.append(original_image)\n",
    "        augmented_y.append(y[i])\n",
    "\n",
    "        for _ in range(num_augmentations):\n",
    "            augmented_image = augmentation_transform(original_image)\n",
    "            augmented_X.append(augmented_image)\n",
    "            augmented_y.append(y[i])  # Augmented image has the same label\n",
    "\n",
    "    return torch.stack(augmented_X), torch.tensor(augmented_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T11:56:00.941828Z",
     "iopub.status.busy": "2025-02-03T11:56:00.941554Z",
     "iopub.status.idle": "2025-02-03T11:56:02.044062Z",
     "shell.execute_reply": "2025-02-03T11:56:02.043108Z",
     "shell.execute_reply.started": "2025-02-03T11:56:00.941808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_original_vs_augmented(dataset, augmentation_transform, num_samples=5):\n",
    "    \"\"\"\n",
    "    Plots original images alongside their augmented versions for the Pins Face Recognition dataset.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(8, num_samples * 2))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        original_image, _ = dataset[i]  # Get image and ignore label\n",
    "        augmented_image = augmentation_transform(original_image)  # Apply augmentation\n",
    "\n",
    "        # Convert tensors to NumPy format correctly\n",
    "        original_image_np = original_image.permute(1, 2, 0).cpu().numpy()  # (C, H, W) -> (H, W, C)\n",
    "        augmented_image_np = augmented_image.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "        # Normalize values if they are outside [0,1] range\n",
    "        original_image_np = (original_image_np - original_image_np.min()) / (original_image_np.max() - original_image_np.min())\n",
    "        augmented_image_np = (augmented_image_np - augmented_image_np.min()) / (augmented_image_np.max() - augmented_image_np.min())\n",
    "\n",
    "        # Plot original image\n",
    "        axes[i, 0].imshow(original_image_np)\n",
    "        axes[i, 0].set_title(\"Original\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        # Plot augmented image\n",
    "        axes[i, 1].imshow(augmented_image_np)\n",
    "        axes[i, 1].set_title(\"Augmented\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ✅ Split dataset into train and test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# ✅ Test the function with the train dataset\n",
    "plot_original_vs_augmented(train_dataset, augmentation_transform, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:08:54.118546Z",
     "iopub.status.busy": "2025-02-03T14:08:54.118238Z",
     "iopub.status.idle": "2025-02-03T14:08:54.130548Z",
     "shell.execute_reply": "2025-02-03T14:08:54.129703Z",
     "shell.execute_reply.started": "2025-02-03T14:08:54.118523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_triplet_model(model, train_loader, val_loader=None, device='cuda', epochs=10, lr=1e-4, weight_decay=1e-4):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "\n",
    "    # Track loss and classification metrics\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], 'train_f1': []\n",
    "    }\n",
    "\n",
    "    if val_loader is not None:\n",
    "        history.update({'val_loss': [], 'val_acc': [], 'val_f1': []})\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        y_true_train, y_pred_train = [], []\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        for anchor, positive, negative in progress_bar:\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            anchor_out, positive_out, negative_out = model(anchor, positive, negative)\n",
    "\n",
    "            # Compute triplet loss\n",
    "            loss = criterion(anchor_out, positive_out, negative_out)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Convert embeddings to binary predictions for classification metrics\n",
    "            pos_dist = torch.norm(anchor_out - positive_out, p=2, dim=1)\n",
    "            neg_dist = torch.norm(anchor_out - negative_out, p=2, dim=1)\n",
    "            preds = (pos_dist < neg_dist).cpu().numpy()\n",
    "            y_true = np.ones_like(preds)\n",
    "\n",
    "            y_true_train.extend(y_true)\n",
    "            y_pred_train.extend(preds)\n",
    "            \n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Compute training metrics\n",
    "        train_acc = accuracy_score(y_true_train, y_pred_train)\n",
    "        train_f1 = f1_score(y_true_train, y_pred_train, zero_division=0)\n",
    "\n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_f1'].append(train_f1)\n",
    "\n",
    "        # Validation Phase (if val_loader is available)\n",
    "        if val_loader is not None:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            y_true_val, y_pred_val = [], []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                progress_bar_val = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "                for anchor, positive, negative in progress_bar_val:\n",
    "                    anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "                    \n",
    "                    anchor_out, positive_out, negative_out = model(anchor, positive, negative)\n",
    "                    loss = criterion(anchor_out, positive_out, negative_out)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    # Convert embeddings to predictions for classification metrics\n",
    "                    pos_dist = torch.norm(anchor_out - positive_out, p=2, dim=1)\n",
    "                    neg_dist = torch.norm(anchor_out - negative_out, p=2, dim=1)\n",
    "                    preds = (pos_dist < neg_dist).cpu().numpy()\n",
    "                    y_true = np.ones_like(preds)\n",
    "\n",
    "                    y_true_val.extend(y_true)\n",
    "                    y_pred_val.extend(preds)\n",
    "                    \n",
    "                    progress_bar_val.set_postfix(loss=loss.item())\n",
    "\n",
    "            # Compute validation metrics\n",
    "            val_acc = accuracy_score(y_true_val, y_pred_val)\n",
    "            val_f1 = f1_score(y_true_val, y_pred_val, zero_division=0)\n",
    "\n",
    "            history['val_loss'].append(val_loss / len(val_loader))\n",
    "            history['val_acc'].append(val_acc)\n",
    "            history['val_f1'].append(val_f1)\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {train_loss / len(train_loader):.4f} | Val Loss: {val_loss / len(val_loader):.4f}\")\n",
    "            print(f\"Train: Acc: {train_acc:.4f}, F1: {train_f1:.4f}\")\n",
    "            print(f\"Val: Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {train_loss / len(train_loader):.4f}\")\n",
    "            print(f\"Train: Acc: {train_acc:.4f}, F1: {train_f1:.4f}\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T16:48:02.588333Z",
     "iopub.status.busy": "2025-02-03T16:48:02.588047Z",
     "iopub.status.idle": "2025-02-03T16:48:02.594626Z",
     "shell.execute_reply": "2025-02-03T16:48:02.593870Z",
     "shell.execute_reply.started": "2025-02-03T16:48:02.588312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TripletNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TripletNetwork, self).__init__()\n",
    "        \n",
    "        base_model = models.resnet50(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-1])  # Remove the final FC layer\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, start_dim=1)  # Flatten to vector\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        return x  # Returns a feature vector instead of a similarity score\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        anchor_embedding = self.forward_once(anchor)\n",
    "        positive_embedding = self.forward_once(positive)\n",
    "        negative_embedding = self.forward_once(negative)\n",
    "        return anchor_embedding, positive_embedding, negative_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tripelet Selection Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_triplets(X, y):\n",
    "    \"\"\"Creates triplets (anchor, positive, negative) for Triplet Loss training.\"\"\"\n",
    "    triplets = []\n",
    "    num_classes = len(torch.unique(y))\n",
    "    class_indices = [torch.where(y == i)[0] for i in range(num_classes)]\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        indices = class_indices[class_id]\n",
    "        num_samples = len(indices)\n",
    "\n",
    "        if num_samples < 2:\n",
    "            continue  # Skip classes with fewer than 2 images\n",
    "\n",
    "        # Create triplets\n",
    "        for _ in range(num_samples // 2):\n",
    "            anchor, positive = np.random.choice(indices, 2, replace=False)\n",
    "            negative_class = random.choice([c for c in range(num_classes) if c != class_id])\n",
    "            negative = random.choice(class_indices[negative_class])\n",
    "\n",
    "            triplets.append((X[anchor], X[positive], X[negative]))\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    anchor_tensor = torch.stack([t[0] for t in triplets])\n",
    "    positive_tensor = torch.stack([t[1] for t in triplets])\n",
    "    negative_tensor = torch.stack([t[2] for t in triplets])\n",
    "\n",
    "    return anchor_tensor, positive_tensor, negative_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_training_metrics(history):\n",
    "    \"\"\"Plots training (and optionally validation) loss, accuracy, and F1-score over epochs.\"\"\"\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "    has_validation = \"val_loss\" in history  # Check if validation metrics exist\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle(\"Training Metrics Over Epochs\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "    # Plot Loss\n",
    "    axes[0].plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    if has_validation:\n",
    "        axes[0].plot(epochs, history[\"val_loss\"], label=\"Validation Loss\", linestyle=\"dashed\")\n",
    "    axes[0].set_title(\"Loss Curve\")\n",
    "    axes[0].set_xlabel(\"Epochs\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    axes[1].plot(epochs, history[\"train_acc\"], label=\"Train Accuracy\")\n",
    "    if has_validation:\n",
    "        axes[1].plot(epochs, history[\"val_acc\"], label=\"Validation Accuracy\", linestyle=\"dashed\")\n",
    "    axes[1].set_title(\"Accuracy Curve\")\n",
    "    axes[1].set_xlabel(\"Epochs\")\n",
    "    axes[1].set_ylabel(\"Accuracy\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    # Plot F1-score\n",
    "    axes[2].plot(epochs, history[\"train_f1\"], label=\"Train F1-score\")\n",
    "    if has_validation:\n",
    "        axes[2].plot(epochs, history[\"val_f1\"], label=\"Validation F1-score\", linestyle=\"dashed\")\n",
    "    axes[2].set_title(\"F1-score Curve\")\n",
    "    axes[2].set_xlabel(\"Epochs\")\n",
    "    axes[2].set_ylabel(\"F1-score\")\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prepreparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Map old labels to new ones\n",
    "new_samples = [(path, class_to_idx_filtered[full_dataset.classes[label]]) for path, label in filtered_samples]\n",
    "\n",
    "# Define transformations without augmentation for original dataset\n",
    "original_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])\n",
    "\n",
    "# Load datasets separately\n",
    "original_dataset = FilteredImageFolder(new_samples, transform=original_transform)  # Original images\n",
    "augmented_dataset = FilteredImageFolder(new_samples, transform=augmented_transform)  # Augmented images\n",
    "\n",
    "# Combine both datasets\n",
    "combined_dataset = ConcatDataset([original_dataset, augmented_dataset])\n",
    "\n",
    "# Extract updated labels for stratification\n",
    "labels = [combined_dataset.datasets[0].targets[i] for i in range(len(combined_dataset.datasets[0]))] + \\\n",
    "         [combined_dataset.datasets[1].targets[i] for i in range(len(combined_dataset.datasets[1]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cros Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T14:08:58.659123Z",
     "iopub.status.busy": "2025-02-03T14:08:58.658800Z",
     "iopub.status.idle": "2025-02-03T15:46:01.414624Z",
     "shell.execute_reply": "2025-02-03T15:46:01.413184Z",
     "shell.execute_reply.started": "2025-02-03T14:08:58.659097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 5-Fold Cross Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(range(len(combined_dataset)), labels)):\n",
    "    print(f\"\\n⭕ Training Fold {fold_idx + 1}...\\n\")\n",
    "\n",
    "    # Create subsets\n",
    "    train_subset = Subset(combined_dataset, train_idx)\n",
    "    test_subset = Subset(combined_dataset, test_idx)\n",
    "\n",
    "    # Apply different transformations for test set (no augmentation)\n",
    "    train_dataset = TripletDataset(train_subset)  # Train dataset with original and augmented images\n",
    "    test_dataset = TripletDataset(test_subset)  # Test dataset with only resizing and normalization\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Define model\n",
    "    model = TripletNetwork().to(device)\n",
    "\n",
    "    # Train model\n",
    "    history = train_triplet_model(model, train_loader, test_loader, device, epochs=20, lr=1e-4)\n",
    "\n",
    "    # Save model for the fold\n",
    "    save_model(model, f\"triplet_model_fold{fold_idx + 1}.pth\")\n",
    "\n",
    "    # Plot training metrics\n",
    "    plot_training_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train On Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-03T16:17:19.024618Z",
     "iopub.status.busy": "2025-02-03T16:17:19.024160Z",
     "iopub.status.idle": "2025-02-03T16:46:13.125591Z",
     "shell.execute_reply": "2025-02-03T16:46:13.124585Z",
     "shell.execute_reply.started": "2025-02-03T16:17:19.024574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert to TripletDataset\n",
    "train_dataset = TripletDataset(combined_dataset)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# Define model\n",
    "model = TripletNetwork().to(device)\n",
    "\n",
    "# Train model (no validation set)\n",
    "history = train_triplet_model(model, train_loader, None, device, epochs=20, lr=1e-4)\n",
    "\n",
    "save_model(model, \"triplet_model.pth\")\n",
    "\n",
    "# Plot training metrics\n",
    "plot_training_metrics(history)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 543939,
     "sourceId": 992580,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
